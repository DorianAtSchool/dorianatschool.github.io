---
---
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TinyLLMs - Dorian Benhamou Goldfajn</title>
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
        {% include nav.html prefix="../" %}

    <main class="container">
        <article class="blog-post">
            <div class="post-header">
                <h2>TinyLLMs</h2>
                <div class="post-meta">
                    <span class="language">Python, Jupyter, JAX</span>
                    <span class="date">Updated: Jan 2026</span>
                </div>
                <a href="https://github.com/DorianAtSchool/TinyLLMs" target="_blank" class="code-link">View Code on GitHub →</a>
            </div>

            <section class="post-content">
                <p class="project-tagline">
                    JAX experiments on tiny character-level language models with clean baselines.
                </p>

                <h3>Goal</h3>
                <p>
                    Study how capacity and training choices affect small character-level language models,
                    using a consistent pipeline and reproducible baselines.
                </p>

                <h3>My Contributions</h3>
                <ul>
                    <li><strong>End-to-end script</strong> - Built a single runner to execute all experiments and log results</li>
                    <li><strong>Data pipeline</strong> - Implemented fixed-length context/target sampling from a character corpus</li>
                    <li><strong>Report</strong> - Produced plots, timing tables, and sample generations in the project report</li>
                </ul>

                <h3>Experiments</h3>
                <ul>
                    <li><strong>Regression warm-up</strong> - Quadratic fit with signed gradient descent</li>
                    <li><strong>Baselines</strong> - Constant and linear context models with cross-entropy loss</li>
                    <li><strong>Nonlinear models</strong> - Single-hidden-layer MLP and a two-layer ReLU variant</li>
                    <li><strong>Generation</strong> - Sampled text from each model to compare structure and coherence</li>
                </ul>

                <h3>Technical Stack</h3>
                <ul>
                    <li>Python, Jupyter - Experimentation and tooling</li>
                    <li>JAX - Model training</li>
                    <li>NumPy, Matplotlib - Data handling and plots</li>
                </ul>
            </section>

            <div class="post-footer">
                <a href="../index.html#projects" class="back-link">← Back to Projects</a>
            </div>
        </article>
    </main>

    <footer>
        <div class="container">
            <p>&copy; 2026 Dorian Benhamou Goldfajn</p>
        </div>
    </footer>

        {% include hiring-modal.html script_src="../hiring-modal.js" %}
</body>
</html>
